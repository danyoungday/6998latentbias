{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
    "\n",
    "from masking import get_overlap_indices, get_masked_and_label\n",
    "from constants import CACHE_DIR, DATA_DIR, DEVICE, CROWSPAIRS_PATH, MSP_RESULTS_DIR, PERP_RESULTS_DIR, FILTERS, GPT2_MODELS, FLAN_T5_MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Perplexity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perplexity(input, model):\n",
    "    out = model(**input, labels=input.input_ids)\n",
    "    loss = out.loss\n",
    "    return torch.exp(loss).item()\n",
    "\n",
    "\n",
    "def compute_all_perplexities(text, counter, model, tokenizer):\n",
    "    # Tokenizer doesn't do this for us\n",
    "    text += tokenizer.eos_token\n",
    "    counter += tokenizer.eos_token\n",
    "\n",
    "    in_tokens = tokenizer(text, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "    counter_tokens = tokenizer(counter, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    perp = get_perplexity(in_tokens, model)\n",
    "    counter_perp = get_perplexity(counter_tokens, model)\n",
    "    return perp, counter_perp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_crowspairs(filter):\n",
    "    df = pd.read_csv(CROWSPAIRS_PATH)\n",
    "    df = df[df[\"stereo_antistereo\"] == \"stereo\"]\n",
    "\n",
    "    # Filter by filter\n",
    "    if filter != \"all\":\n",
    "        df = df[df[\"bias_type\"] == filter]\n",
    "\n",
    "    return df[\"sent_more\"].tolist(), df[\"sent_less\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity_run(model_list, filters, verbose=True, force=False, save=True):\n",
    "\n",
    "    for model_name in model_list:\n",
    "        # Set up model for trial\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=CACHE_DIR)\n",
    "        model = model.to(DEVICE)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=CACHE_DIR)\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "        # Go through each filter and get results\n",
    "        for filter in filters:\n",
    "            path = os.path.join(PERP_RESULTS_DIR, f\"{filter}/{model_name}\")\n",
    "            if os.path.exists(path) and not force:\n",
    "                print(f\"Already exists results for model {model_name}, bias type {filter}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"Creating perp results for {model_name}, bias type {filter}\")\n",
    "\n",
    "            # Load data\n",
    "            texts, counters = parse_crowspairs(filter)\n",
    "\n",
    "            base_perps = []\n",
    "            counter_perps = []\n",
    "            for text, counter in tqdm(list(zip(texts, counters))):\n",
    "                base_perp, counter_perp = compute_all_perplexities(text, counter, model, tokenizer)\n",
    "                base_perps.append(base_perp)\n",
    "                counter_perps.append(counter_perp)\n",
    "\n",
    "            base_perps = np.array(base_perps)\n",
    "            counter_perps = np.array(counter_perps)\n",
    "            \n",
    "            if save:\n",
    "                # Save hidden states\n",
    "                if not os.path.exists(path):\n",
    "                    print(f\"Creating directory {path}\")\n",
    "                    os.makedirs(path)\n",
    "                np.save(os.path.join(path, \"pos-perps.npy\"), base_perps)\n",
    "                np.save(os.path.join(path, \"neg-perps.npy\"), counter_perps)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"median perp ratio: {sorted(base_perps / counter_perps)[len(base_perps) // 2]}\")\n",
    "                print(np.median(base_perps), np.median(counter_perps))\n",
    "        \n",
    "        # I don't know if this does anything. It didn't before\n",
    "        del model\n",
    "        del tokenizer\n",
    "        torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_run(GPT2_MODELS, FILTERS, verbose=True, force=True, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder-Decoder Perplexity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_loss(string, label, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Feeds text and input into tokenizer then model and outputs the loss.\n",
    "    \"\"\"\n",
    "    tokens = tokenizer(string, return_tensors=\"pt\").to(model.device)\n",
    "    label = tokenizer(label, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    out = model(**tokens, labels=label)\n",
    "    return torch.exp(out[\"loss\"]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_msp_losses(model_names, filters, save=True, force=False):\n",
    "    \"\"\"\n",
    "    Generates losses for 2 groups for positive and negative for a total of 4:\n",
    "        unmasked group: does msp with the bias word guaranteed to not be masked\n",
    "        control group: guarantees the bias word is masked\n",
    "    We want the difference between the unmasked and control \n",
    "    \"\"\"\n",
    "\n",
    "    for model_name in model_names:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=CACHE_DIR, model_max_length=512)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name, cache_dir=CACHE_DIR)\n",
    "        model.to(\"mps\")\n",
    "        model.eval()\n",
    "\n",
    "        for filter in filters:\n",
    "            # If we already have something saved here, skip it\n",
    "            path = os.path.join(MSP_RESULTS_DIR, f\"{filter}/{model_name}\")\n",
    "            if os.path.exists(path) and not force:\n",
    "                print(f\"Already exists msp results for {model_name}:{filter}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"Creating msp results for {model_name}, bias type {filter}\")\n",
    "\n",
    "            df = pd.read_csv(CROWSPAIRS_PATH)\n",
    "            df = df[df[\"stereo_antistereo\"] == \"stereo\"]\n",
    "            if filter != \"all\":\n",
    "                df = df[df[\"bias_type\"] == filter]\n",
    "            all_pos = df[\"sent_more\"].to_list()\n",
    "            all_neg = df[\"sent_less\"].to_list()\n",
    "\n",
    "            #all_pos, all_neg = filter_samples(all_pos, all_neg, max_len=3)\n",
    "            print(f\"pos len: {len(all_pos)}, neg len: {len(all_neg)}\")\n",
    "\n",
    "            pos_losses = []\n",
    "            neg_losses = []\n",
    "            for pos, neg in tqdm(zip(all_pos, all_neg), total=len(all_pos)):\n",
    "\n",
    "                # Create masks, get masked strings and labels\n",
    "                pos_mask, neg_mask = get_overlap_indices(pos, neg)\n",
    "                pos_masked, pos_label = get_masked_and_label(pos, pos_mask)\n",
    "                neg_masked, neg_label = get_masked_and_label(neg, neg_mask)\n",
    "                # Run masked strings and labels through model\n",
    "                pos_perp = get_model_loss(pos_masked, pos_label, model, tokenizer)\n",
    "                neg_perp = get_model_loss(neg_masked, neg_label, model, tokenizer)\n",
    "                pos_losses.append(pos_perp)\n",
    "                neg_losses.append(neg_perp)\n",
    "            \n",
    "            pos_losses = np.array(pos_losses)\n",
    "            neg_losses = np.array(neg_losses)\n",
    "            print(f\"median diff: {np.median(pos_losses/neg_losses)}\")\n",
    "            print(f\"median pos perp: {np.median(pos_losses)}, median neg perp: {np.median(neg_losses)}\")\n",
    "            \n",
    "            if save:\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "\n",
    "                np.save(os.path.join(MSP_RESULTS_DIR, f\"{filter}/{model_name}/pos-perps\"), pos_losses)\n",
    "                np.save(os.path.join(MSP_RESULTS_DIR, f\"{filter}/{model_name}/neg-perps\"), neg_losses)\n",
    "\n",
    "        del model\n",
    "        del tokenizer\n",
    "        torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#msp_model_list = [\"google/flan-t5-small\", \"google/flan-t5-base\", \"google/flan-t5-large\"]\n",
    "msp_model_list = [\"t5-small\", \"t5-base\", \"t5-large\"]\n",
    "filters = [\"all\"] + list(pd.read_csv(CROWSPAIRS_PATH)[\"bias_type\"].unique())\n",
    "save_msp_losses(msp_model_list, filters, force=False, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc. Results Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(model_name, filter, msp=True):\n",
    "    if msp:\n",
    "        path = os.path.join(MSP_RESULTS_DIR, f\"{filter}/{model_name}\")\n",
    "    else:\n",
    "        path = os.path.join(PERP_RESULTS_DIR, f\"{filter}/{model_name}\")\n",
    "    all_pos_losses = np.load(os.path.join(path, \"pos-perps.npy\"))\n",
    "    all_neg_losses = np.load(os.path.join(path, \"neg-perps.npy\"))\n",
    "\n",
    "    return all_pos_losses, all_neg_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "want pos loss - neg loss to be negative value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diffs_filters(filters, model_name):\n",
    "    mean_diffs = []\n",
    "    for filter in filters:\n",
    "        pos_losses, neg_losses = load_results(model_name, filter)\n",
    "        mean_diff = np.mean(pos_losses - neg_losses)\n",
    "        mean_diffs.append(mean_diff)\n",
    "    plt.bar(filters, mean_diffs)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.gca().yaxis.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def boxplots(filters, model_name, msp=True):\n",
    "    mean_diffs = {}\n",
    "    for filter in filters:\n",
    "        pos_losses, neg_losses = load_results(model_name, filter, msp)\n",
    "        mean_diffs[filter] = pos_losses - neg_losses\n",
    "    plt.axhline(y=0)\n",
    "    plt.boxplot(mean_diffs.values(), labels=mean_diffs.keys(), showfliers=False)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.gca().yaxis.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [\"all\"] + list(pd.read_csv(CROWSPAIRS_PATH)[\"bias_type\"].unique())\n",
    "boxplots(filters, \"t5-large\")\n",
    "boxplots(filters, \"gpt2-xl\", msp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = list(pd.read_csv(CROWSPAIRS_PATH)[\"bias_type\"].unique())\n",
    "filters = [filters] + [[filt] for filt in filters]\n",
    "model_name = \"flan-t5-small\"\n",
    "pos = []\n",
    "neg = []\n",
    "for filter in filters:\n",
    "    pos_losses, neg_losses = load_results(model_name, filter)\n",
    "    pos.append(np.mean(pos_losses))\n",
    "    neg.append(np.mean(neg_losses))\n",
    "filters = [\"all\" if len(filt) != 1 else filt[0] for filt in filters]\n",
    "width = 0.4\n",
    "x = np.arange(len(filters))\n",
    "plt.bar(x-width/2, pos, width=width, label=\"pos\")\n",
    "plt.bar(x+width/2, neg, width=width, label=\"neg\")\n",
    "plt.xticks(x, filters, rotation=90)\n",
    "plt.gca().yaxis.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
