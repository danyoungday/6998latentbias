{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForMaskedLM, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"mps\"\n",
    "\n",
    "CACHE_DIR = os.path.join(os.getcwd(), \"cache_dir\")\n",
    "DATA_DIR = os.path.join(os.getcwd(), \"data\")\n",
    "CROWSPAIRS_PATH = os.path.join(DATA_DIR, \"crows_pairs_anonymized.csv\")\n",
    "RESULTS_DIR = os.path.join(os.getcwd(), \"results/msp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_differences(A, B, mask):\n",
    "    A_masked = A.detach().clone().squeeze()\n",
    "    B_masked = B.detach().clone().squeeze()\n",
    "    a_start, a_end = 0, len(A) - 1\n",
    "    b_start, b_end = 0, len(B) - 1\n",
    "    while A_masked[a_start] == B_masked[b_start]:\n",
    "        a_start += 1\n",
    "        b_start += 1\n",
    "    while A_masked[a_end] == B_masked[b_end]:\n",
    "        a_end -= 1\n",
    "        b_end -= 1\n",
    "\n",
    "    A_masked[a_start:a_end+1] = mask\n",
    "    B_masked[b_start:b_end+1] = mask\n",
    "    return A_masked.unsqueeze(0), B_masked.unsqueeze(0)\n",
    "\n",
    "\n",
    "def get_perplexity(input_ids, model, tokenizer, model_type):\n",
    "    if model_type == \"decoder\":\n",
    "        out = model(input_ids, labels=input_ids)\n",
    "    elif model_type == \"encoder-decoder\":\n",
    "        decoder_input_ids = tokenizer(\"\", return_tensors=\"pt\").input_ids.to(model.device)\n",
    "        out = model(input_ids, decoder_input_ids=decoder_input_ids, labels=decoder_input_ids)\n",
    "    else:\n",
    "        assert False, \"Give a correct model type\"\n",
    "    loss = out.loss\n",
    "    return torch.exp(loss).item()\n",
    "\n",
    "\n",
    "def compute_all_perplexities(text, counter, model, tokenizer, model_type):\n",
    "    \n",
    "    # Add the EOS token if we're decoding\n",
    "    if model_type == \"decoder\":\n",
    "        text += tokenizer.eos_token\n",
    "        counter += tokenizer.eos_token\n",
    "\n",
    "    in_tokens = tokenizer(text, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    counter_tokens = tokenizer(counter, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    mask_tokens = mask_differences(in_tokens, counter_tokens, tokenizer.unk_token_id)[0]\n",
    "\n",
    "    perp = get_perplexity(in_tokens, model, tokenizer, model_type)\n",
    "    counter_perp = get_perplexity(counter_tokens, model, tokenizer, model_type)\n",
    "    masked_perp = get_perplexity(mask_tokens, model, tokenizer, model_type)\n",
    "    return perp, counter_perp, masked_perp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_crowspairs(filter=None):\n",
    "    df = pd.read_csv(CROWSPAIRS_PATH)\n",
    "    df = df[df[\"stereo_antistereo\"] == \"stereo\"]\n",
    "\n",
    "    # Filter by filter\n",
    "    if filter:\n",
    "        df = df[df[\"bias_type\"] == filter]\n",
    "\n",
    "    return df[\"sent_more\"].tolist(), df[\"sent_less\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msp(trials, filters, verbose=True):\n",
    "    for trial in trials:\n",
    "        # Set up model for trial\n",
    "        if trial[\"model_type\"] == \"decoder\":\n",
    "            model = AutoModelForCausalLM.from_pretrained(trial[\"model_name\"], cache_dir=CACHE_DIR)\n",
    "        elif trial[\"model_type\"] == \"encoder-decoder\":\n",
    "            model = AutoModelForSeq2SeqLM.from_pretrained(trial[\"model_name\"], cache_dir=CACHE_DIR)\n",
    "        else:\n",
    "            assert False, \"Input a valid model type\"\n",
    "        model = model.to(DEVICE)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(trial[\"model_name\"], cache_dir=CACHE_DIR)\n",
    "\n",
    "        # Go through each filter and get results\n",
    "        for filter in filters:\n",
    "            \n",
    "            path = os.path.join(RESULTS_DIR, f\"{filter}/{trial['trial_name']}\")\n",
    "            if os.path.exists(path):\n",
    "                print(f\"Already exists results for model {trial['model_name']}, bias type {filter}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"Creating MSP results for {trial['model_name']}, bias type {filter}\")\n",
    "\n",
    "            # Load data\n",
    "            if filter == \"all\":\n",
    "                filter = None\n",
    "            texts, counters = parse_crowspairs(filter)\n",
    "\n",
    "            base_perps = []\n",
    "            counter_perps = []\n",
    "            masked_perps = []\n",
    "            for text, counter in tqdm(list(zip(texts, counters))):\n",
    "                base_perp, counter_perp, masked_perp = compute_all_perplexities(text, counter, model, tokenizer, trial[\"model_type\"])\n",
    "                base_perps.append(base_perp)\n",
    "                counter_perps.append(counter_perp)\n",
    "                masked_perps.append(masked_perp)\n",
    "\n",
    "            base_perps = np.array(base_perps)\n",
    "            counter_perps = np.array(counter_perps)\n",
    "            masked_perps = np.array(masked_perps)\n",
    "            \n",
    "            # Save hidden states\n",
    "            print(f\"Creating directory {path}\")\n",
    "            os.makedirs(path)\n",
    "            np.save(os.path.join(path, \"base_perps.npy\"), base_perps)\n",
    "            np.save(os.path.join(path, \"counter_perps.npy\"), counter_perps)\n",
    "            np.save(os.path.join(path, \"masked_perps.npy\"), masked_perps)\n",
    "\n",
    "            if verbose:\n",
    "                print(base_perps.mean(), counter_perps.mean(), masked_perps.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_trials = [\n",
    "    {\"trial_name\": \"gpt2\",\n",
    "     \"model_name\": \"gpt2\",\n",
    "     \"model_type\": \"decoder\"},\n",
    "     {\"trial_name\": \"gpt2-large\",\n",
    "     \"model_name\": \"gpt2-large\",\n",
    "     \"model_type\": \"decoder\"},\n",
    "     {\"trial_name\": \"gpt2-xl\",\n",
    "     \"model_name\": \"gpt2-xl\",\n",
    "     \"model_type\": \"decoder\"},\n",
    "     {\"trial_name\": \"gpt2-medium\",\n",
    "     \"model_name\": \"gpt2-medium\",\n",
    "     \"model_type\": \"decoder\"},\n",
    "]\n",
    "flan_t5_trials = [\n",
    "    {\"trial_name\": \"flan-t5-small\",\n",
    "     \"model_name\": \"google/flan-t5-small\",\n",
    "     \"model_type\": \"encoder-decoder\"},\n",
    "     {\"trial_name\": \"flan-t5-base\",\n",
    "     \"model_name\": \"google/flan-t5-base\",\n",
    "     \"model_type\": \"encoder-decoder\"},\n",
    "     {\"trial_name\": \"flan-t5-large\",\n",
    "     \"model_name\": \"google/flan-t5-large\",\n",
    "     \"model_type\": \"encoder-decoder\"}\n",
    "]\n",
    "df = pd.read_csv(CROWSPAIRS_PATH)\n",
    "filters = [\"all\"] + list(df[\"bias_type\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msp(gpt2_trials, filters)\n",
    "msp(flan_t5_trials, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_models = [\"gpt2\", \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\"]\n",
    "roberta_models = [\"roberta-base\", \"roberta-large\"]\n",
    "flan_t5_models = [\"flan-t5-small\", \"flan-t5-base\", \"flan-t5-large\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all & 3.82 & 8.86 & 8.0 & 7.91 \\\\\n",
      "race-color & 5.05 & 12.22 & 12.42 & 5.54 \\\\\n",
      "socioeconomic & 10.23 & 11.55 & 9.02 & 10.82 \\\\\n",
      "gender & -22.8 & -0.01 & -11.22 & 8.81 \\\\\n",
      "disability & 24.94 & 20.49 & 22.46 & 13.65 \\\\\n",
      "nationality & -3.53 & 0.4 & 1.83 & 3.73 \\\\\n",
      "sexual-orientation & 31.61 & 23.59 & 26.9 & 20.24 \\\\\n",
      "physical-appearance & 22.53 & 22.96 & 17.78 & 20.11 \\\\\n",
      "religion & 18.69 & 18.63 & 19.08 & 20.64 \\\\\n",
      "age & -22.34 & -29.11 & -20.3 & -19.05 \\\\\n",
      "(                          gpt2  gpt2-medium  gpt2-large    gpt2-xl\n",
      "all                   3.824816     8.862363    8.004009   7.909845\n",
      "race-color            5.047342    12.223942   12.418284   5.535150\n",
      "socioeconomic        10.232997    11.548631    9.018133  10.821410\n",
      "gender              -22.801524    -0.009595  -11.223390   8.809298\n",
      "disability           24.941194    20.488231   22.459889  13.652316\n",
      "nationality          -3.532796     0.401660    1.829124   3.726966\n",
      "sexual-orientation   31.608135    23.591473   26.903229  20.239925\n",
      "physical-appearance  22.527207    22.962502   17.778294  20.110663\n",
      "religion             18.686614    18.627393   19.084205  20.644021\n",
      "age                 -22.335444   -29.111083  -20.298205 -19.049663,                             gpt2  gpt2-medium   gpt2-large      gpt2-xl\n",
      "all                  5830.070667  1448.110077  1734.003209  1382.392569\n",
      "race-color           7247.946783  1435.671701  2120.610364  1662.924721\n",
      "socioeconomic        4432.842880   976.097814  1311.038177  1016.832121\n",
      "gender               8960.883533  3815.467015  2798.880406  2537.017345\n",
      "disability           5456.063480  1185.813633  1508.126593  1218.422362\n",
      "nationality          5483.225246   790.540783  1224.229480   845.424114\n",
      "sexual-orientation   2485.924219   973.977026  1065.837556   746.056036\n",
      "physical-appearance  3342.747555   845.314504  1099.920784   906.752012\n",
      "religion             4442.026527   937.325809  1415.439710  1031.089759\n",
      "age                   776.609864   515.250738   571.870740   495.571939)\n"
     ]
    }
   ],
   "source": [
    "def msp_results(model_names, filters):\n",
    "    rows = []\n",
    "    rows_mask = []\n",
    "    for filter in filters:\n",
    "        row = {}\n",
    "        row_mask = {}\n",
    "        s = filter + \" \"\n",
    "        for model_name in model_names:\n",
    "            path = os.path.join(os.getcwd(), f\"results/msp/{filter}/{model_name}\")\n",
    "            base_perps = np.load(os.path.join(path, \"base_perps.npy\"))\n",
    "            counter_perps = np.load(os.path.join(path, \"counter_perps.npy\"))\n",
    "            masked_perps = np.load(os.path.join(path, \"masked_perps.npy\"))\n",
    "            diff_counter = np.mean(counter_perps) - np.mean(base_perps)\n",
    "            diff_mask = np.mean(masked_perps) - np.mean(base_perps)\n",
    "            s += f\"& {round(diff_counter, 2)} \"\n",
    "            row[model_name] = diff_counter\n",
    "            row_mask[model_name] = diff_mask\n",
    "        s += \"\\\\\\\\\"\n",
    "        print(s)\n",
    "\n",
    "        rows.append(row)\n",
    "        rows_mask.append(row_mask)\n",
    "\n",
    "    df_counter = pd.DataFrame(rows, index=filters)\n",
    "    df_mask = pd.DataFrame(rows_mask, index=filters)\n",
    "\n",
    "    return df_counter, df_mask\n",
    "\n",
    "print(msp_results(gpt2_models, filters)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
